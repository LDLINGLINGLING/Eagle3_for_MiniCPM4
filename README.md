# EAGLE Training Implementation (TrainEAGLE3)

ä¸€ä¸ªé«˜æ•ˆçš„EAGLEï¼ˆæ¨æµ‹è§£ç ï¼‰æ¨¡å‹åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ï¼Œæ”¯æŒå¤§è¯­è¨€æ¨¡å‹çš„åŠ é€Ÿæ¨ç†ä¼˜åŒ–ã€‚

## ğŸ¯ é¡¹ç›®ç®€ä»‹

EAGLEï¼ˆExtrapolation Algorithm for Greater Language-model Efficiencyï¼‰æ˜¯ä¸€ç§åˆ›æ–°çš„æ¨æµ‹è§£ç æ–¹æ³•ï¼Œé€šè¿‡è®­ç»ƒè½»é‡çº§çš„è‰ç¨¿æ¨¡å‹æ¥é¢„æµ‹ç›®æ ‡æ¨¡å‹çš„ä¸‹ä¸€ä¸ªtokenï¼Œä»è€Œæ˜¾è‘—æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚
æœ¬é¡¹ç›®ä¸ºMiniCPM4é€‚é…EAGLE3çš„æŠ•æœºè§£ç æ¨¡å‹ã€‚

### è®­ç»ƒæ•ˆæœ
ä»¥ä¸‹è¡¨æ ¼æ˜¯EAGLE3åœ¨MiniCPM4ä¸Šçš„ä½¿ç”¨14000æ¡alpacaæ•°æ®è®­ç»ƒåçš„æµ‹è¯•ç»“æœ
| é¢„æµ‹ä½ç½® | å‡†ç¡®ç‡ (%) | å‡†ç¡®ç‡æ ‡å‡†å·® | æŸå¤± | æŸå¤±æ ‡å‡†å·® |
|---------|-----------|-------------|------|-----------|
| ä½ç½® 0  | 48.05     | Â±7.58       | 0.8946 | Â±0.3383 |
| ä½ç½® 1  | 48.72     | Â±7.64       | 0.8844 | Â±0.3379 |
| ä½ç½® 2  | 48.68     | Â±8.03       | 0.8839 | Â±0.3390 |
| ä½ç½® 3  | 48.40     | Â±8.15       | 0.8884 | Â±0.3411 |
| ä½ç½® 4  | 48.09     | Â±8.18       | 0.8935 | Â±0.3434 |
| ä½ç½® 5  | 47.34     | Â±8.15       | 0.9006 | Â±0.3467 |
| ä½ç½® 6  | 46.79     | Â±7.89       | 0.9093 | Â±0.3490 |
### æ ¸å¿ƒæ€æƒ³
- ğŸ¯ **æ¨æµ‹è§£ç **ï¼šä½¿ç”¨å°æ¨¡å‹é¢„æµ‹å¤§æ¨¡å‹çš„è¾“å‡ºï¼Œå‡å°‘æ¨ç†å»¶è¿Ÿ
- ğŸ”„ **å¤šæ­¥é¢„æµ‹**ï¼šä¸€æ¬¡æ€§é¢„æµ‹å¤šä¸ªtokenï¼Œæé«˜å¹¶è¡Œåº¦
- ğŸ“Š **è¯æ±‡è¡¨å‹ç¼©**ï¼šåŸºäºé¢‘ç‡ç»Ÿè®¡å‹ç¼©è¾“å‡ºè¯æ±‡è¡¨ï¼Œå‡å°‘è®¡ç®—é‡
- ğŸ¤ **çŸ¥è¯†è’¸é¦**ï¼šè®©è‰ç¨¿æ¨¡å‹å­¦ä¹ ç›®æ ‡æ¨¡å‹çš„è¾“å‡ºåˆ†å¸ƒ

## âœ¨ ä¸»è¦ç‰¹æ€§

- âš¡ **åˆ†å¸ƒå¼è®­ç»ƒ**ï¼šåŸºäºDeepSpeedçš„å¤šå¡/å¤šæœºè®­ç»ƒæ”¯æŒ
- ğŸ”§ **æ··åˆç²¾åº¦**ï¼šæ”¯æŒFP16/BF16ï¼Œé™ä½æ˜¾å­˜ä½¿ç”¨
- ğŸ’¾ **æ–­ç‚¹ç»­è®­**ï¼šè‡ªåŠ¨æ£€æŸ¥ç‚¹ä¿å­˜å’Œæ¢å¤
- ğŸ“ˆ **å®æ—¶ç›‘æ§**ï¼šé›†æˆWandbè®­ç»ƒç›‘æ§
- ğŸ›ï¸ **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§æ¨¡å‹æ¶æ„å’Œè®­ç»ƒç­–ç•¥
- ğŸ§ª **å®Œæ•´æµ‹è¯•**ï¼šåŒ…å«å•å¡æµ‹è¯•è„šæœ¬

## ğŸ“¦ ç¯å¢ƒè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **GPU**: NVIDIA V100/A100/H100ç­‰ï¼Œå»ºè®®8å¡æˆ–ä»¥ä¸Š
- **æ˜¾å­˜**: æ¯å¡è‡³å°‘24GBï¼ˆå–å†³äºæ¨¡å‹å¤§å°ï¼‰
- **å†…å­˜**: å»ºè®®256GBä»¥ä¸Š

### è½¯ä»¶ä¾èµ–
```bash
# Python 3.8+
pip install torch>=1.13.0
pip install transformers>=4.21.0
pip install deepspeed>=0.9.0
pip install datasets>=2.0.0
pip install wandb
pip install numpy
pip install tqdm
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/LDLINGLINGLING/Eagle3_for_MiniCPM4.git
cd Eagle3_for_MiniCPM4/eagle/traineagle3

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è®¾ç½®Wandbï¼ˆå¯é€‰ï¼‰
export WANDB_API_KEY="your_wandb_api_key"
```

### 2. æ•°æ®å‡†å¤‡
æ•°æ®æ ¼å¼ä¸ºJSONLï¼Œæ¯è¡ŒåŒ…å«å¯¹è¯æ•°æ®ï¼š
```json
{
  "id": "unique_id",
  "conversations": [
    {"from": "human", "value": "ç”¨æˆ·é—®é¢˜1"},
    {"from": "gpt", "value": "åŠ©æ‰‹å›ç­”2"},
    {"from": "human", "value": "ç”¨æˆ·é—®é¢˜1"},
    {"from": "gpt", "value": "åŠ©æ‰‹å›ç­”2"}
  ]
}
```

### 3. é…ç½®æ–‡ä»¶
ç¡®ä¿ä»¥ä¸‹é…ç½®æ–‡ä»¶å­˜åœ¨ï¼š
- `ds_config.json`: DeepSpeedé…ç½®
- `config.json`: EAGLEæ¨¡å‹é…ç½®

### 4. å¼€å§‹è®­ç»ƒ
```bash
# å•æœºå¤šå¡è®­ç»ƒ
deepspeed --num_gpus=8 main.py \
    --basepath /path/to/base/model \
    --trainpath /path/to/train.jsonl \
    --testpath /path/to/test.jsonl \
    --savedir ./checkpoints \
    --deepspeed_config ds_config.json

# å¤šæœºè®­ç»ƒ
deepspeed --num_gpus=8 --num_nodes=2 --node_rank=0 \
    --master_addr=192.168.1.100 --master_port=29500 \
    main.py [å‚æ•°åŒä¸Š]
```

## ğŸ“‹ è¯¦ç»†ä½¿ç”¨è¯´æ˜

### è®­ç»ƒå‚æ•°è¯´æ˜

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | æè¿° |
|------|------|--------|------|
| `--basepath` | str | `/data1/minicpm4/` | é¢„è®­ç»ƒç›®æ ‡æ¨¡å‹è·¯å¾„ |
| `--trainpath` | str | - | è®­ç»ƒæ•°æ®è·¯å¾„ |
| `--testpath` | str | - | æµ‹è¯•æ•°æ®è·¯å¾„ |
| `--savedir` | str | `'0'` | æ¨¡å‹ä¿å­˜ç›®å½• |
| `--deepspeed_config` | str | - | DeepSpeedé…ç½®æ–‡ä»¶ |
| `--local_rank` | int | `-1` | åˆ†å¸ƒå¼è®­ç»ƒæœ¬åœ°rank |

### é…ç½®æ–‡ä»¶è¯¦è§£

#### DeepSpeedé…ç½® (ds_config.json)
```json
{
  "fp16": {"enabled": true},
  "zero_optimization": {"stage": 2},
  "gradient_accumulation_steps": 4,
  "train_micro_batch_size_per_gpu": 2,
  "optimizer": {
    "type": "AdamW",
    "params": {"lr": 0.0001}
  }
}
```

#### EAGLEæ¨¡å‹é…ç½® (config.json)
```json
{
  "hidden_size": 4096,
  "num_hidden_layers": 32,
  "draft_vocab_size": 16000,
  "length": 8
}
```

### è®­ç»ƒæµç¨‹

1. **æ•°æ®æ‰«æ**ï¼šåˆ†æè®­ç»ƒæ•°æ®ï¼Œæ„å»ºå‹ç¼©è¯æ±‡è¡¨
2. **æ¨¡å‹åˆå§‹åŒ–**ï¼šåŠ è½½ç›®æ ‡æ¨¡å‹å’ŒEAGLEæ¨¡å‹
3. **åˆ†å¸ƒå¼è®¾ç½®**ï¼šé…ç½®DeepSpeedåˆ†å¸ƒå¼è®­ç»ƒ
4. **è®­ç»ƒå¾ªç¯**ï¼š
   - æ•°æ®é¢„å¤„ç†å’Œæ‰¹æ¬¡æ„å»º
   - ç›®æ ‡æ¨¡å‹å‰å‘ä¼ æ’­ï¼ˆè·å–ç›‘ç£ä¿¡å·ï¼‰
   - EAGLEæ¨¡å‹è®­ç»ƒï¼ˆå¤šæ­¥é¢„æµ‹ï¼‰
   - æŸå¤±è®¡ç®—å’Œåå‘ä¼ æ’­
   - å‚æ•°æ›´æ–°å’Œæ£€æŸ¥ç‚¹ä¿å­˜

### æµ‹è¯•å’Œè¯„ä¼°

```bash
# å•å¡æµ‹è¯•
python test.py \
    --model_path ./checkpoints/state_39/pytorch_model.bin \
    --basepath /path/to/base/model \
    --testpath /path/to/test.jsonl \
    --batch_size 2 \
    --save_results ./test_results
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
traineagle3/
â”œâ”€â”€ main.py              # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test.py              # å•å¡æµ‹è¯•è„šæœ¬
â”œâ”€â”€ cnets.py             # EAGLEæ¨¡å‹å®ç°
â”œâ”€â”€ configs.py           # é…ç½®ç±»å®šä¹‰
â”œâ”€â”€ ds_config.json       # DeepSpeedé…ç½®
â”œâ”€â”€ config.json          # EAGLEæ¨¡å‹é…ç½®
â”œâ”€â”€ requirements.txt     # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md           # é¡¹ç›®è¯´æ˜
```

## ğŸ”§ æ ¸å¿ƒæ¨¡å—è¯´æ˜

### cnets.py - EAGLEæ¨¡å‹å®ç°
- `Model`ç±»ï¼šä¸»è¦çš„EAGLEæ¨¡å‹å®ç°
- `scandata`æ–¹æ³•ï¼šæ•°æ®ç»Ÿè®¡å’Œè¯æ±‡è¡¨å‹ç¼©
- `forward`æ–¹æ³•ï¼šå¤šæ­¥é¢„æµ‹è®­ç»ƒé€»è¾‘
- `dataprepare`æ–¹æ³•ï¼šæ•°æ®é¢„å¤„ç†

### configs.py - é…ç½®ç®¡ç†
- `EConfig`ç±»ï¼šEAGLEæ¨¡å‹é…ç½®
- æ”¯æŒä»JSONæ–‡ä»¶åŠ è½½é…ç½®
- å‚æ•°éªŒè¯å’Œé»˜è®¤å€¼è®¾ç½®

### main.py - è®­ç»ƒä¸»æµç¨‹
- DeepSpeedåˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®
- æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
- è®­ç»ƒå¾ªç¯å’Œæ£€æŸ¥ç‚¹ç®¡ç†
- Wandbç›‘æ§é›†æˆ

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### å†…å­˜ä¼˜åŒ–
- **ZeRO Stage 2**ï¼šåˆ†ç‰‡ä¼˜åŒ–å™¨çŠ¶æ€
- **æ¢¯åº¦ç´¯ç§¯**ï¼šå‡å°‘é€šä¿¡é¢‘ç‡
- **æ··åˆç²¾åº¦**ï¼šFP16/BF16è®­ç»ƒ
- **è¯æ±‡è¡¨å‹ç¼©**ï¼šå‡å°‘è¾“å‡ºç»´åº¦

### è®¡ç®—ä¼˜åŒ–
- **FlashAttention**ï¼šé«˜æ•ˆæ³¨æ„åŠ›è®¡ç®—
- **å¤šæ­¥é¢„æµ‹**ï¼šå¹¶è¡Œtokenç”Ÿæˆ
- **æ‰¹æ¬¡å¤„ç†**ï¼šæé«˜GPUåˆ©ç”¨ç‡

### é€šä¿¡ä¼˜åŒ–
- **é‡å é€šä¿¡**ï¼šè®¡ç®—å’Œé€šä¿¡å¹¶è¡Œ
- **æ¢¯åº¦å‹ç¼©**ï¼šå‡å°‘ä¼ è¾“æ•°æ®é‡
- **åˆ†å±‚é€šä¿¡**ï¼šä¼˜åŒ–å¤šæœºé€šä¿¡

## ğŸ› å¸¸è§é—®é¢˜

### 1. CUDAå†…å­˜ä¸è¶³
```bash
# å‡å°‘æ‰¹æ¬¡å¤§å°
"train_micro_batch_size_per_gpu": 1

# å¢åŠ æ¢¯åº¦ç´¯ç§¯
"gradient_accumulation_steps": 8

# å¯ç”¨CPUå¸è½½
"offload_optimizer": {"device": "cpu"}
```

### 2. FlashAttentioné”™è¯¯
```bash
# ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
export CUDA_VISIBLE_DEVICES=0
# æ¨¡å‹ä¼šè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ•°æ®ç±»å‹
```

### 3. æ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
ls checkpoints/state_*/

# æ¸…ç†æŸåçš„æ£€æŸ¥ç‚¹
rm -rf checkpoints/state_broken/
```

### 4. åˆ†å¸ƒå¼è®­ç»ƒé—®é¢˜
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥
ping master_node_ip

# ç¡®ä¿ç«¯å£å¯ç”¨
netstat -an | grep 29500

# æ£€æŸ¥NCCLç‰ˆæœ¬
python -c "import torch; print(torch.cuda.nccl.version())"
```

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

### Wandbç›‘æ§
- è®­ç»ƒæŸå¤±å’Œå‡†ç¡®ç‡
- GPUåˆ©ç”¨ç‡å’Œå†…å­˜ä½¿ç”¨
- å­¦ä¹ ç‡å˜åŒ–
- å„å±‚é¢„æµ‹ç²¾åº¦

### æœ¬åœ°æ—¥å¿—
- æ§åˆ¶å°è¾“å‡ºï¼šå®æ—¶è®­ç»ƒä¿¡æ¯
- æ£€æŸ¥ç‚¹ï¼šè‡ªåŠ¨ä¿å­˜è®­ç»ƒçŠ¶æ€
- é”™è¯¯æ—¥å¿—ï¼šå¼‚å¸¸å’Œè­¦å‘Šä¿¡æ¯

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç å’Œæå‡ºæ”¹è¿›å»ºè®®ï¼

1. Forké¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. æ¨é€åˆ°åˆ†æ”¯
5. åˆ›å»ºPull Request

**Happy Training! ğŸš€**
